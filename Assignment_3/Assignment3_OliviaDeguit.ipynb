{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2023F-T3 AML 3104 - Neural Networks and Deep Learning 01__\n",
    "\n",
    "__Submitted to: Professor Ishant Gupta__\n",
    "\n",
    "__Submitted by: Olivia Deguit__\n",
    "\n",
    "__Assignment 3: Decision Tree and Classification Matrix__\n",
    "\n",
    "Github URL: https://github.com/ovdlambton/NeuralNetwork/blob/main/Assignment_3/Assignment3_OliviaDeguit.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Web Source References:__*\n",
    "\n",
    "https://towardsdatascience.com/building-an-intuition-for-the-decision-tree-algorithm-75e0786e86d\n",
    "\n",
    "https://towardsdatascience.com/performance-metrics-for-classification-machine-learning-problems-97e7e774a007\n",
    "\n",
    "https://medium.com/analytics-vidhya/decision-trees-explained-in-simple-steps-39ee1a6b00a2\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/09/precision-recall-machine-learning/\n",
    "\n",
    "\n",
    "*__Book Reference:__*\n",
    "\n",
    "O’Reilly Practical Statistics for Data Scientists 50+ Essential Concepts using R and Python by Peter Bruce, Andrew Bruce & Peter Gedeck\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q1. Describe the decision tree classifier algorithm and how it works to make predictions*\n",
    "\n",
    "Answer: A decision tree classifier is like a flowchart that helps in making decisions based on information. It starts by looking at the data and splitting it into groups that are as similar as possible. It does this by asking yes-or-no questions about the data (like \"Is this person older than 18?\"). Each time it splits the data, it picks the question that makes the groups the most similar. When it reached to the point that it can't split anymore, each end point (or leaf) represents a group that is given a certain label. If a decision tree is too detailed, it might not work well with new data, so sometimes we make it simpler (this is called pruning). While one decision tree is easy to understand, using many trees together (like in random forests) can make better predictions, but they are less transparent in how they arrive at decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification*\n",
    "\n",
    "Answer: See below for the explanation:\n",
    "\n",
    "- Selecting the best feature to split the data using a criterion like Gini impurity or information gain.\n",
    "\n",
    "- Splitting the dataset into subsets based on the feature that provides the best split.\n",
    "\n",
    "- Recursively repeating the process for each child node until the stopping criteria are met (e.g., maximum depth of the tree, minimum number of samples in a node, or when all instances in a node have the same class).\n",
    "\n",
    "- Making predictions by traversing the tree from the root to a leaf node that represents the majority class among the training instances filtered down to that leaf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q3: Explain how a decision tree classifier can be used to solve a binary classification problem.*\n",
    "\n",
    "Answer: A decision tree classifier can solve a binary classification problem by creating a binary tree where each node splits the data into two groups based on a feature value. When making predictions, an instance is passed down the tree according to these binary decisions until it reaches a leaf node. The class assigned to the leaf node is the prediction for the instance. Evaluation can also be performed to assess the model’s performance using different metrices such as accuracy, precision, recall, F1-score or ROC curves. Tuning can also be applied to the model by adjusting hyperparameter to optimize the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q4: Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions.*\n",
    "\n",
    "Answer: The geometric intuition behind decision tree classification is like creating a series of \"splits\" in a feature space. Imagine the feature space as a multi-dimensional space, and each decision (or split) in the tree corresponds to a boundary that divides this space into regions associated with different classes.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "1. Splits =>  At each node of the tree, the algorithm selects a feature and a threshold value to split the data. Think of a decision tree as a map of how to separate things. At each step (node) in the tree, it picks a feature for example (like height) and a value (like 5 feet tall). This creates a line or boundary in the space of all possible heights. If you're taller than 5 feet, you go one way; if you're shorter, you go the other way.\n",
    "So, decision trees are like making a series of height-based divisions, and by following these divisions, you can classify things based on their height or any other relevant features.\n",
    "\n",
    "2. Regions => As you traverse down the tree, you continue to split the space into smaller regions. Each region is associated with a specific class based on the majority class of the training data within that region.\n",
    "\n",
    "3. Prediction => To make a prediction for a new data point, you start at the root of the tree and follow the path of splits based on the feature values of the data point. When you reach a leaf node, the class assigned to that leaf node is the predicted class for the input data point.\n",
    "\n",
    "In summary, decision tree classification divides the feature space into regions associated with different classes, and predictions are made by determining which region the input data point falls into. This geometric approach allows decision trees to capture complex decision boundaries in the data and make predictions based on these boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model.*\n",
    "\n",
    "Answer: A confusion matrix is a table used to evaluate the performance of a classification model. It shows the true positives, false positives, true negatives, and false negatives. This matrix is useful for measuring precision, recall, specificity, accuracy, and F1 score of the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it.*\n",
    "\n",
    "__True Positive (TP)__: The cases in which the model correctly predicted the positive class.\n",
    "\n",
    "__True Negative (TN)__: The cases in which the model correctly predicted the negative class.\n",
    "\n",
    "__False Positive (FP)__: The cases in which the model incorrectly predicted the positive class\n",
    "\n",
    "__False Negative (FN)__: The cases in which the model incorrectly predicted the negative class\n",
    "\n",
    "__*Formula below:*__\n",
    "\n",
    "$$ Accuracy = {TP + TN \\over TP + TN + FP + FN} $$\n",
    "\n",
    "\n",
    "$$ Precision = {TP\\over (TP+FP)} $$\n",
    "\n",
    "\n",
    "$$ Recall = {TP\\over (TP+FN)} $$\n",
    "\n",
    "\n",
    "$$ F1 Score = 2 * {(precision * recall) \\over (precision + recall)} $$\n",
    "\n",
    "*Confusion Matrix performance metric calculations that I performed in the NLP Subject for Term 3. It is important to identify TP, TN , FP and FN accordingly to be able to come up with correct metrics used to evaluate the performance of a classification model.*\n",
    "\n",
    "![Confusion Matrix](https://raw.githubusercontent.com/ovdlambton/NeuralNetwork/main/Assignment_3/Confusion_Matrix.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done.*\n",
    "\n",
    "Answer: Choosing an appropriate evaluation metric is crucial because different metrics provide different insights into the model's performance. For instance, accuracy might not be appropriate for imbalanced classes. One should consider the problem's context, the cost of false positives vs. false negatives, and the distribution of the classes. Common practice involves looking at the business (business case) or application objective and then selecting a metric that aligns with that objective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q8. Provide an example of a classification problem where precision is the most important metric, and explain why*\n",
    "\n",
    "Answer: In the medical field, precision is crucial for diagnosing rare diseases like certain cancers because a false positive whereby a healthy person incorrectly identified as having the disease can lead to unnecessary and harmful treatments. Ensuring high precision means that when a patient is diagnosed with the disease, the diagnosis is likely accurate, avoiding undue emotional stress and avoiding costly, potentially invasive medical interventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Q9. Provide an example of a classification problem where recall is the most important metric and explain why.*\n",
    "\n",
    "Answer: In the medical field, recall is most critical in scenarios where missing out on a true positive can be life-threatening, such as the early detection of a highly treatable disease like sepsis. If a patient with sepsis is not identified promptly, the condition can quickly escalate, leading to severe complications or death.\n",
    "In this case, a high recall rate means the test identifies most or all actual cases of sepsis. It's more acceptable to have some false positives (where the test incorrectly indicates sepsis) because the cost of missing a true case far outweighs the inconvenience and cost of additional testing to rule out the disease in false-positive cases. High recall ensures that almost no true cases go undetected, which is crucial when the disease requires rapid intervention."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
